{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1, 3, 0.5, -10], \n",
    "                 [15, 20, 0.3, 3], \n",
    "                 [0.7,-12,-0.1, 5.]\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1. ,   3. ,   0.5, -10. ],\n",
       "       [ 15. ,  20. ,   0.3,   3. ],\n",
       "       [  0.7, -12. ,  -0.1,   5. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is usally a good practice to remove the mean of the raw data to center data on zero and remove any bias from the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean= [ 5.56666667  3.66666667  0.23333333 -0.66666667]\n",
      "Std Deviation= [ 6.67149825 13.0724477   0.24944383  6.64997911]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean=\", data.mean(axis=0))\n",
    "print(\"Std Deviation=\", data.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Mean= [ 7.40148683e-17  0.00000000e+00 -1.48029737e-16 -7.40148683e-17]\n",
      "Std Deviation= [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# mean removal\n",
    "data_standardized = preprocessing.scale(data)\n",
    "print(\"\\n Mean=\", data_standardized.mean(axis=0))\n",
    "print(\"Std Deviation=\", data_standardized.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.68450391, -0.05099785,  1.06904497, -1.40351318],\n",
       "       [ 1.41397524,  1.24944721,  0.26726124,  0.55138018],\n",
       "       [-0.72947132, -1.19844937, -1.33630621,  0.852133  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min-Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax scaled data\n",
      " [[0.02097902 0.46875    1.         0.        ]\n",
      " [1.         1.         0.66666667 0.86666667]\n",
      " [0.         0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# min max scaling\n",
    "data_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "data_scaled = data_scaler.fit_transform(data)\n",
    "print(\"MinMax scaled data\\n\", data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1 normalized data:\n",
      " [[ 0.06896552  0.20689655  0.03448276 -0.68965517]\n",
      " [ 0.39164491  0.52219321  0.0078329   0.07832898]\n",
      " [ 0.03932584 -0.6741573  -0.00561798  0.28089888]]\n"
     ]
    }
   ],
   "source": [
    "# normalization\n",
    "data_normalized = preprocessing.normalize(data, norm=\"l1\")\n",
    "print('\\nL1 normalized data:\\n', data_normalized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data [[  1.    3.    0.5 -10. ]\n",
      " [ 15.   20.    0.3   3. ]\n",
      " [  0.7 -12.   -0.1   5. ]]\n",
      "\n",
      "Binarized data:\n",
      " [[0. 1. 0. 0.]\n",
      " [1. 1. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# binarization\n",
    "data_binarized = preprocessing.Binarizer(threshold=2).transform(data)\n",
    "print('Original Data', data)\n",
    "print('\\nBinarized data:\\n', data_binarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In supervised learning is usual to have labels in human-readable form. It is often necessary to transform those labels to numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class mapping:\n",
      "audi 0\n",
      "bmw 1\n",
      "ford 2\n",
      "toyota 3\n"
     ]
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "input_classes = ['audi', 'ford', 'audi', 'toyota', 'ford', 'bmw']\n",
    "label_encoder.fit(input_classes)\n",
    "\n",
    "# print classes\n",
    "print('\\nClass mapping:')\n",
    "for i, item in enumerate(label_encoder.classes_):\n",
    "    print(item, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enumerate at 0x1a216147e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enumerate(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['audi', 'bmw', 'ford', 'toyota'], dtype='<U6')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels = ['toyota', 'ford', 'audi']\n",
      "\n",
      "coded labels = [3, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# transform a set of classes\n",
    "labels = ['toyota', 'ford', 'audi']\n",
    "encoded_labels = label_encoder.transform(labels)\n",
    "print('\\nLabels =', labels)\n",
    "print('\\ncoded labels =', list(encoded_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
