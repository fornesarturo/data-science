{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have a dataset of 50 startups with their profits, location and different types of expenses. We would like to create a model to predict their profits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, we need to download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we have categorical data, we need to encode it somehow into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, 3] = labelencoder.fit_transform(X[:, 3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fornesarturo/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/fornesarturo/anaconda3/envs/ds/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5344151e+05,\n",
       "        1.0114555e+05, 4.0793454e+05]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoiding the Dummy Variable\n",
    "X = X[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 1.0000000e+00, 1.6534920e+05, 1.3689780e+05,\n",
       "        4.7178410e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.6259770e+05, 1.5137759e+05,\n",
       "        4.4389853e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.5344151e+05, 1.0114555e+05,\n",
       "        4.0793454e+05]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a1d97e2b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD8CAYAAAC2PJlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAF29JREFUeJzt3X+MXeV95/H317ZMMpUCBpuU+tc4jbMSqboR3BIn2m5TSMFEVcxKVGs0ErMJ2tHSJKtStYtZS0H9YSm/JLSoCcls8WKys/woosFalXW9JFv+CT/GaQCTDfUEbDOB4kEmKNJokxC++8d5Bq6HsWfu47meueP3S7o653zPc849j481nznnPPdOZCaSJNVYttAHIEnqXYaIJKmaISJJqmaISJKqGSKSpGqGiCSpmiEiSapmiEiSqhkikqRqKxb6AObb6tWrs7+/f6EPQ5J6yoEDB17NzDWdbrfkQqS/v5/R0dGFPgxJ6ikRcaRmO29nSZKqGSKSpGqGiCSpmiEiSapmiEiSqhkiktTrRkagvx+WLWumIyNn7K2X3BBfSTqrjIzA0BBMTjbLR440ywADA11/e69EJKmX7dz5doBMmZxs6meAISJJvezo0c7q88wQkaRetmFDZ/V5ZohIUi/btQv6+k6s9fU19TPAEJGkXjYwAMPDsHEjRDTT4eEz8lAdHJ0lSb1vYOCMhcZ0XolIkqoZIpKkaoaIJKmaISJJqmaISJKqGSKSpGqGiCSpmiEiSapmiEiSqhkikqRqhogkqdqsIRIRuyPiWEQcbKt9KCIei4jvR8RoRFxW6hERt0fEWEQ8HRGXtG0zGBGHymuwrX5pRDxTtrk9IqLUz4+I/aX9/ohYNb9dlySdrrlcidwFbJ1W+xLwZ5n5IeDzZRngamBzeQ0Bd0ATCMCtwIeBy4Bb20LhjtJ2arup99oBPJKZm4FHyrIkaRGZNUQy81Hg+PQy8J4yfy7wUpnfBtydjceA8yLiIuAqYH9mHs/M14D9wNay7j2Z+d3MTOBu4Jq2fe0p83va6pKkRaL2q+D/CNgXEV+hCaKPlvpa4MW2duOldqr6+Ax1gPdm5ssAmflyRFxYeaySpC6pfbB+I3BTZq4HbgLuLPWYoW1W1DsSEUPl2czoxMREp5tLkirVhsgg8GCZ/xua5xzQXEmsb2u3juZW16nq62aoA7xSbndRpsdOdjCZOZyZrcxsrVmzpqpDkqTO1YbIS8DvlPnLgUNlfi9wfRmltQV4vdyS2gdcGRGrygP1K4F9Zd1PI2JLGZV1PfBQ276mRnENttUlSYvErM9EIuIe4GPA6ogYpxll9e+B/xIRK4D/RzO6CuDvgE8AY8Ak8CmAzDweEX8BPFna/XlmTj2sv5FmBNi7gYfLC+ALwP0RcQNwFPiD6l5KkroimkFRS0er1crR0dGFPgxJ6ikRcSAzW51u5yfWJUnVDBFJUjVDRJJUzRCRJFUzRCRJ1QwRSVI1Q0SSVM0QkSRVM0QkSdUMEUlSNUNEklTNEJEkVTNEJEnVDBFJUjVDRJJUzRCRJFUzRCRpvoyMQH8/LFvWTEdGFvqIum7WP48rSZqDkREYGoLJyWb5yJFmGWBgYOGOq8u8EpGk+bBz59sBMmVysqkvYYaIJM2Ho0c7qy8RhogkzYcNGzqrLxGGiCTNh127oK/vxFpfX1NfwgwRSZoPAwMwPAwbN0JEMx0eXtIP1cHRWZI0fwYGlnxoTOeViCSpmiEiSao2a4hExO6IOBYRB6fVPxcRz0XEsxHxpbb6LRExVtZd1VbfWmpjEbGjrb4pIh6PiEMRcV9ErCz1c8ryWFnfPx8dliTNn7lcidwFbG0vRMTvAtuA38zMDwJfKfWLge3AB8s2X4uI5RGxHPgqcDVwMXBdaQvwReC2zNwMvAbcUOo3AK9l5vuB20o7SdIiMmuIZOajwPFp5RuBL2Tmz0qbY6W+Dbg3M3+WmS8AY8Bl5TWWmc9n5s+Be4FtERHA5cADZfs9wDVt+9pT5h8ArijtJUmLRO0zkQ8Av11uM/1DRPxWqa8FXmxrN15qJ6tfAPwkM9+YVj9hX2X966X9O0TEUESMRsToxMREZZckSZ2qDZEVwCpgC/CnwP3lKmGmK4WsqDPLuhOLmcOZ2crM1po1a2Y7dknSPKkNkXHgwWw8AbwJrC719W3t1gEvnaL+KnBeRKyYVqd9m7L+XN55W02StIBqQ+RbNM8yiIgPACtpAmEvsL2MrNoEbAaeAJ4ENpeRWCtpHr7vzcwEvgNcW/Y7CDxU5veWZcr6b5f2kqRFYtZPrEfEPcDHgNURMQ7cCuwGdpdhvz8HBssP+Gcj4n7gB8AbwGcy85dlP58F9gHLgd2Z+Wx5i5uBeyPiL4F/BO4s9TuBb0bEGM0VyPZ56K8kaR7FUvvlvtVq5ejo6EIfhiT1lIg4kJmtTrfzE+uSpGqGiCSpmiEiSapmiEiSqhkikqRqhogkqZohIkmqZohIkqoZIpKkaoaIJKmaISJJqmaISJKqGSKSpGqGiCSpmiEiSapmiEiSqhki0lIxMgL9/bBsWTMdGVnoI9JZYNY/jyupB4yMwNAQTE42y0eONMsAAwMLd1xa8rwSkZaCnTvfDpApk5NNXeoiQ0RaCo4e7awuzRNDRFoKzj+/s7o0TwwRSVI1Q0RaCo4f76wuzRNDRFoKNmzorC7NE0NEWgp27YK+vhNrfX1NXeoiQ0RaCgYGYHgYNm6EiGY6POxnRNR1s4ZIROyOiGMRcXCGdX8SERkRq8tyRMTtETEWEU9HxCVtbQcj4lB5DbbVL42IZ8o2t0dElPr5EbG/tN8fEavmp8vSEjUwAIcPw5tvNlMDRGfAXK5E7gK2Ti9GxHrg94D2gehXA5vLawi4o7Q9H7gV+DBwGXBrWyjcUdpObTf1XjuARzJzM/BIWZYkLSKzhkhmPgrMNMTjNuA/AdlW2wbcnY3HgPMi4iLgKmB/Zh7PzNeA/cDWsu49mfndzEzgbuCatn3tKfN72uqSpEWi6plIRHwS+HFmPjVt1Vrgxbbl8VI7VX18hjrAezPzZYAyvfAUxzMUEaMRMToxMVHRI0lSjY5DJCL6gJ3A52daPUMtK+odyczhzGxlZmvNmjWdbi5JqlRzJfLrwCbgqYg4DKwDvhcRv0pzJbG+re064KVZ6utmqAO8Um53UabHKo5VktRFHYdIZj6TmRdmZn9m9tMEwSWZ+c/AXuD6MkprC/B6uRW1D7gyIlaVB+pXAvvKup9GxJYyKut64KHyVnuBqVFcg211SdIiMZchvvcA3wX+RUSMR8QNp2j+d8DzwBjwX4E/BMjM48BfAE+W15+XGsCNwF+XbX4EPFzqXwB+LyIO0YwC+0JnXZMkdVs0g6KWjlarlaOjowt9GJLUUyLiQGa2Ot3OT6xLkqoZIpKkaoaIJKmaISJJqmaISJKqGSKSpGqGiCSpmiEiSapmiEiSqhkikqRqhogkqZohIkmqZohIkqoZIpKkaoaIJKmaISJJqmaISJKqGSKSpGqGiCSpmiEiSapmiEiSqhkikqRqhogkqZohIkmqZohIkqoZIpKkarOGSETsjohjEXGwrfbliPhhRDwdEX8bEee1rbslIsYi4rmIuKqtvrXUxiJiR1t9U0Q8HhGHIuK+iFhZ6ueU5bGyvn++Oi1Jmh9zuRK5C9g6rbYf+I3M/E3gn4BbACLiYmA78MGyzdciYnlELAe+ClwNXAxcV9oCfBG4LTM3A68BN5T6DcBrmfl+4LbSTpK0iMwaIpn5KHB8Wu3vM/ONsvgYsK7MbwPuzcyfZeYLwBhwWXmNZebzmflz4F5gW0QEcDnwQNl+D3BN2772lPkHgCtKe0nSIjEfz0Q+DTxc5tcCL7atGy+1k9UvAH7SFkhT9RP2Vda/Xtq/Q0QMRcRoRIxOTEycdockSXNzWiESETuBN4CRqdIMzbKifqp9vbOYOZyZrcxsrVmz5tQHLUmaNytqN4yIQeD3gSsyc+qH+ziwvq3ZOuClMj9T/VXgvIhYUa422ttP7Ws8IlYA5zLttpokaWFVXYlExFbgZuCTmTnZtmovsL2MrNoEbAaeAJ4ENpeRWCtpHr7vLeHzHeDasv0g8FDbvgbL/LXAt9vCSpK0CMx6JRIR9wAfA1ZHxDhwK81orHOA/eVZ92OZ+R8y89mIuB/4Ac1trs9k5i/Lfj4L7AOWA7sz89nyFjcD90bEXwL/CNxZ6ncC34yIMZorkO3z0F9J0jyKpfbLfavVytHR0YU+DEnqKRFxIDNbnW7nJ9YlSdUMEUlSNUNEklTNEJEkVTNEJEnVDBFJUjVDRJJUzRCRJFUzRHR2GxmB/n5YtqyZjozMtoWkNtVfwCj1vJERGBqCyfL1b0eONMsAAwMLd1xSD/FKRGevnTvfDpApk5NNXdKcGCI6ex092lld0jsYIjp7bdjQWV3SOxgiOnvt2gV9fSfW+vqauqQ5MUR09hoYgOFh2LgRIprp8LAP1aUOODpLZ7eBAUNDOg1eiUiSqhki0kz8EKI0J97OkqbzQ4jSnHklIk3nhxClOTNEtDgspttHfghRmjNDRAtv6vbRkSOQ+fbto4UKEj+EKM2ZIaKFt9huH/khRGnODBEtvMV2+8gPIUpz5ugsLbwNG5pbWDPVF4ofQpTmxCsRLTxvH0k9a9YQiYjdEXEsIg621c6PiP0RcahMV5V6RMTtETEWEU9HxCVt2wyW9ociYrCtfmlEPFO2uT0i4lTvoSXI20dSz5rLlchdwNZptR3AI5m5GXikLANcDWwuryHgDmgCAbgV+DBwGXBrWyjcUdpObbd1lvfQUjQwAIcPw5tvNlMDROoJs4ZIZj4KHJ9W3gbsKfN7gGva6ndn4zHgvIi4CLgK2J+ZxzPzNWA/sLWse09mfjczE7h72r5meg9J0iJR+0zkvZn5MkCZXljqa4EX29qNl9qp6uMz1E/1Hu8QEUMRMRoRoxMTE5VdkiR1ar4frMcMtayodyQzhzOzlZmtNWvWdLq5JKlSbYi8Um5FUabHSn0cWN/Wbh3w0iz1dTPUT/Ue6gWL6WtMJHVNbYjsBaZGWA0CD7XVry+jtLYAr5dbUfuAKyNiVXmgfiWwr6z7aURsKaOyrp+2r5neQ4vdYvsaE0ldE83z7FM0iLgH+BiwGniFZpTVt4D7gQ3AUeAPMvN4CYK/ohlhNQl8KjNHy34+DfznsttdmfnfSr1FMwLs3cDDwOcyMyPigpneY7YOtVqtHB0dnWv/1Q39/TN/eHDjxmbklaRFJyIOZGar4+1mC5FeY4gsAsuWNVcg00U0Q3glLTq1IeIn1jX//BZc6axhiGj++TUm0lnDENH882tMpLOG3+Kr7vBbcKWzglcikqRqhogkqZohIkmqZohIkqoZIpKkaoaIJKmaISJJqmaISJKqGSKSpGqGiCSpmiEiSapmiEiSqhkikqRqhogkqZohIkmqZohIkqoZIpKkaoaIJKmaISJJqmaISJKqGSIAIyPQ3w/LljXTkZGFPiJJ6gmnFSIRcVNEPBsRByPinoh4V0RsiojHI+JQRNwXEStL23PK8lhZ39+2n1tK/bmIuKqtvrXUxiJix+kc60mNjMDQEBw5ApnNdGjIIJGkOagOkYhYC/xHoJWZvwEsB7YDXwRuy8zNwGvADWWTG4DXMvP9wG2lHRFxcdnug8BW4GsRsTwilgNfBa4GLgauK23n186dMDl5Ym1ysqlLkk7pdG9nrQDeHRErgD7gZeBy4IGyfg9wTZnfVpYp66+IiCj1ezPzZ5n5AjAGXFZeY5n5fGb+HLi3tJ1fR492VpckvaU6RDLzx8BXgKM04fE6cAD4SWa+UZqNA2vL/FrgxbLtG6X9Be31aducrD6/NmzorC5Jesvp3M5aRXNlsAn4NeBXaG49TZdTm5xkXaf1mY5lKCJGI2J0YmJitkM/0a5d0Nd3Yq2vr6lLkk7pdG5nfRx4ITMnMvMXwIPAR4Hzyu0tgHXAS2V+HFgPUNafCxxvr0/b5mT1d8jM4cxsZWZrzZo1nfViYACGh2HjRohopsPDTf1kHM0lScDphchRYEtE9JVnG1cAPwC+A1xb2gwCD5X5vWWZsv7bmZmlvr2M3toEbAaeAJ4ENpfRXitpHr7vPY3jPbmBATh8GN58s5nOFiCO5pIk4PSeiTxO84D8e8AzZV/DwM3AH0fEGM0zjzvLJncCF5T6HwM7yn6eBe6nCaD/BXwmM39Znpt8FtgH/F/g/tJ2YTmaS5LeEs3FwNLRarVydHS0e2+wbFlzBTJdRHMlI0k9KCIOZGar0+38xHqnHM0lSW8xRDrlaC5Jeosh0qma0VyStEStmL2J3mFgwNCQJLwSkSSdBkNEklTNEJEkVTNEJEnVDBFJUrUl94n1iJgAjiz0cZym1cCrC30QXWLfepN9602d9G1jZnb4DbZLMESWgogYrfn6gV5g33qTfetNZ6Jv3s6SJFUzRCRJ1QyRxWl4oQ+gi+xbb7JvvanrffOZiCSpmlcikqRqhkgXRcRNEfFsRByMiHsi4l3lz/0+HhGHIuK+8qd/KX8e+L6IGCvr+9v2c0upPxcRV7XVt5baWETs6HJfdkfEsYg42FY7PyL2l77sj4hVpR4RcXs5rqcj4pK2bQZL+0MRMdhWvzQininb3F7+5PJJ3+MM9O3LEfHDcvx/GxHnta3r6HzUnPNu9q1t3Z9EREbE6rLc8+et1D9XzsOzEfGltnpPn7eI+FBEPBYR34+I0Yi4rNQX9rxlpq8uvIC1wAvAu8vy/cC/K9PtpfZ14MYy/4fA18v8duC+Mn8x8BRwDrAJ+BGwvLx+BLwPWFnaXNzF/vxr4BLgYFvtS8COMr8D+GKZ/wTwMBDAFuDxUj8feL5MV5X5VWXdE8BHyjYPA1ef6j3OQN+uBFaU+S+29a3j89HpOe9230p9Pc2fnj4CrF5C5+13gf8NnFOWL1wq5w34+7Z/308A/2cxnLeu/MDx9VaIvFhO4ArgfwJX0XzwZ+qH00eAfWV+H/CRMr+itAvgFuCWtv3uK9u9tW2pn9CuS33qn/af+jngojJ/EfBcmf8GcN30dsB1wDfa6t8otYuAH7bV32p3svfodt+mrfs3wMhM/86znY9yDjs652eib8ADwL8EDvN2iPT8eaP5wf/xGdr1/Hkr7/tv2/6t/8diOG/ezuqSzPwx8BXgKPAy8DpwAPhJZr5Rmo3ThA28HTqU9a8DF7TXp21zsvqZ9N7MfBmgTC8s9U6PeW2Zn14/1XucSZ+m+W0NOu/bBXR+zrsqIj4J/Dgzn5q2aimctw8Av11uM/1DRPxWqff8eQP+CPhyRLxI87PllunHM+1Yz8h5M0S6pNxL3EZz6fxrwK8AV8/QdGp4XJxkXaf1xWDJ9CUidgJvACNTpRma1fbtjPc7IvqAncDnZ1p9kuPppfO2gubWzRbgT4H7y/3+nj5vxY3ATZm5HrgJuHOW4zkj580Q6Z6PAy9k5kRm/gJ4EPgocF5ETP1FyXXAS2V+nOY+NWX9ucDx9vq0bU5WP5NeiYiLAMr0WKl3eszjZX56/VTv0XXlQeTvAwNZru/pvG+v0vk576Zfp/nF5qmIOFyO53sR8aun6EMvnbdx4MFsPAG8SfP9Ub1+3gAGaX6OAPwNcNn04ynO6HkzRLrnKLAlIvrKb0JXAD8AvgNcW9oMAg+V+b1lmbL+2+UH115gexkRsgnYTPNQ7ElgcxlBspLmAd/eM9Cvdu3HPL0v15dRI1uA18ul8T7gyohYVa7UrqS5z/wy8NOI2FL+ra5n5n+X9vfoqojYCtwMfDIzJ9tWdXQ+yjns9Jx3TWY+k5kXZmZ/ZvbT/EC5JDP/mSVw3oBvAZcDRMQHaB6Wv0qPn7fiJeB3yvzlwKG241m489aNh12+3npg9WfAD4GDwDdpRoa8j+Y/7xjNbxNTo0jeVZbHyvr3te1nJ80IkucooyhK/RPAP5V1O7vcl3tonu38guYHzw0094EfKf+ZHwHOL20D+Go5rmeAVtt+Pl36OAZ8qq3eKv9OPwL+irc/CDvje5yBvo3R3E/+fnl9vfZ81JzzbvZt2vrDvP1gfSmct5XAfy/H9D3g8qVy3oB/RfNc9SngceDSxXDe/MS6JKmat7MkSdUMEUlSNUNEklTNEJEkVTNEJEnVDBFJUjVDRJJUzRCRJFX7/zoh8764MEJIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_pred, y_test, color = 'red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103015.20159796, 132582.27760815, 132447.73845175,  71976.09851258,\n",
       "       178537.48221056, 116161.24230166,  67851.69209676,  98791.73374687,\n",
       "       113969.43533013, 167921.06569551])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,\n",
       "        81229.06,  97483.56, 110352.25, 166187.94])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is it necessary to include all the variables??\n",
    "#### What if we have thousand variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's reduce the number of Variables using Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Mar 2019</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:29:12</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.013e+04</td> <td> 6884.820</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  6.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  198.7888</td> <td> 3371.007</td> <td>    0.059</td> <td> 0.953</td> <td>-6595.030</td> <td> 6992.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -41.8870</td> <td> 3256.039</td> <td>   -0.013</td> <td> 0.990</td> <td>-6604.003</td> <td> 6520.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.45e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Wed, 13 Mar 2019   Prob (F-statistic):           1.34e-27\n",
       "Time:                        11:29:12   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1063.\n",
       "Df Residuals:                      44   BIC:                             1074.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\n",
       "x1           198.7888   3371.007      0.059      0.953   -6595.030    6992.607\n",
       "x2           -41.8870   3256.039     -0.013      0.990   -6604.003    6520.229\n",
       "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
       "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the optimal model using Backward Elimination\n",
    "import statsmodels.formula.api as sm\n",
    "X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)\n",
    "#we need the above step because OLS from statsmodel does not include the intercept\n",
    "List_aux = [0, 1, 2, 3, 4, 5]\n",
    "X_opt = X[:, List_aux]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To do it in a programatic way you need to select the variable with the highes p-value and exclude it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.44417839e-09 9.53242901e-01 9.89794124e-01 2.57877192e-21\n",
      " 6.07737327e-01 1.22676927e-01]\n"
     ]
    }
   ],
   "source": [
    "print(regressor_OLS.pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indx=np.argmax(regressor_OLS.pvalues)\n",
    "List_aux.pop(indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 4, 5]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But here we will do it manually in order to see what is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Mar 2019</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:29:17</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.011e+04</td> <td> 6647.870</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+04</td> <td> 6.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  220.1585</td> <td> 2900.536</td> <td>    0.076</td> <td> 0.940</td> <td>-5621.821</td> <td> 6062.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Wed, 13 Mar 2019   Prob (F-statistic):           8.49e-29\n",
       "Time:                        11:29:17   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\n",
       "x1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\n",
       "x2             0.8060      0.046     17.606      0.000       0.714       0.898\n",
       "x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n",
       "x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
       "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
       "Kurtosis:                       5.563   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_opt = X[:, List_aux]\n",
    "X_opt = X[:, [0,1,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Mar 2019</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:29:18</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Wed, 13 Mar 2019   Prob (F-statistic):           4.53e-30\n",
       "Time:                        11:29:18   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 3, 4, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Mar 2019</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:29:20</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Wed, 13 Mar 2019   Prob (F-statistic):           2.16e-31\n",
       "Time:                        11:29:20   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 3, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Mar 2019</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:29:21</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.903e+04</td> <td> 2537.897</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     849.8\n",
       "Date:                Wed, 13 Mar 2019   Prob (F-statistic):           3.50e-32\n",
       "Time:                        11:29:21   Log-Likelihood:                -527.44\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      48   BIC:                             1063.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
       "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
       "==============================================================================\n",
       "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
       "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
       "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 3]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most important variable is R+D!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
